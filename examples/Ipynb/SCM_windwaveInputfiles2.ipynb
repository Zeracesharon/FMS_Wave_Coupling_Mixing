{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1c60b-0721-43b7-aff6-d5814b60172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# ============================================================\n",
    "# Build Stokes-drift-bands + wind stress forcing NetCDF\n",
    "#   - Input structure: 5mps for intial mixed layer depth 10m\n",
    "#       LES_DIR/\n",
    "#          021/LESout.mat\n",
    "#          031/LESout.mat\n",
    "#          ...\n",
    "#   - Output: one NetCDF per case\n",
    "#\n",
    "# CHANGE in this version:\n",
    "#   - Output time axis is REGULAR every 10 minutes, starting from 0 minutes\n",
    "#   - All fields are interpolated onto that 10-min grid\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------\n",
    "# USER SETTINGS\n",
    "# -----------------------\n",
    "LES_DIR = \"/archive/bgr/Datasets/LES/MoreHurr/TS05_ML10/LT/\"\n",
    "OUT_DIR = \"/archive/Qian.Xiao/Qian.Xiao/MOM6_kappa_ePBL/ice/10m_Forcing/\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "CASE_LIST = [\n",
    "    \"021\",\"031\",\"036\",\"038\",\"040\",\"042\",\"044\",\"046\",\"048\",\"050\",\n",
    "    \"051\",\"053\",\"055\",\"057\",\"059\",\"061\",\"063\",\"065\",\"071\",\"081\",\n",
    "]\n",
    "\n",
    "# 读 wavenumber（推荐用你已有的14-band模板 forcing 文件）\n",
    "TEMPLATE_NC = None  # e.g. \"/path/to/template_14bands.nc\"\n",
    "WAVENUMBERS = [0.006, 0.01 , 0.02 , 0.04 , 0.06 , 0.08 , 0.1  , 0.2  , 0.4  , 0.6  ,\n",
    "               0.8  , 1.   , 2.   , 4. ]  # length 14\n",
    "\n",
    "# Lat/Lon 必须 -10,10\n",
    "LAT_2 = np.array([-10.0, 10.0], dtype=\"f8\")\n",
    "LON_2 = np.array([-10.0, 10.0], dtype=\"f8\")\n",
    "\n",
    "# Fit controls\n",
    "ZMAX_FIT  = 100.0       # meters (top 100m)\n",
    "RIDGE_LAM = 1e-8        # small ridge\n",
    "FILL_US   = 1.0e32      # fillvalue for Usx/Usy\n",
    "\n",
    "TIME_UNITS = \"minutes since 2011-04-01 00:00:00\"\n",
    "TIME_CAL   = \"gregorian\"\n",
    "\n",
    "# Output time grid control\n",
    "DT_MIN_OUT = 10  # minutes, fixed output interval\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# helpers\n",
    "# -----------------------\n",
    "def load_les_mat(case_id: str, root_dir: str):\n",
    "    \"\"\"Load LESout.mat from root_dir/<case_id>/LESout.mat\"\"\"\n",
    "    f = os.path.join(root_dir, case_id, \"LESout.mat\")\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f)\n",
    "    m = sio.loadmat(f)\n",
    "\n",
    "    t_sec = np.asarray(m[\"t\"]).squeeze().astype(\"f8\")   # seconds\n",
    "    z     = np.asarray(m[\"z\"]).T.squeeze().astype(\"f8\") # meters, positive down\n",
    "\n",
    "    Us = np.asarray(m[\"Us\"]).astype(\"f8\")              # (Nt, Nz)\n",
    "    Vs = np.asarray(m[\"Vs\"]).astype(\"f8\")              # (Nt, Nz)\n",
    "\n",
    "    tau13l = np.asarray(m[\"tau13l\"]).astype(\"f8\")      # (Nt, Nz?) we use [:,0]\n",
    "    tau23l = np.asarray(m[\"tau23l\"]).astype(\"f8\")\n",
    "\n",
    "    return t_sec, z, Us, Vs, tau13l, tau23l\n",
    "\n",
    "\n",
    "def get_k(template_nc, wavenumbers):\n",
    "    if template_nc is not None and os.path.exists(template_nc):\n",
    "        with Dataset(template_nc, \"r\") as nc:\n",
    "            k = np.asarray(nc.variables[\"wavenumber\"][:], dtype=\"f8\")\n",
    "        if k.size != 14:\n",
    "            raise ValueError(f\"Template wavenumber size != 14: {k.size}\")\n",
    "        return k\n",
    "\n",
    "    if wavenumbers is None:\n",
    "        raise ValueError(\"TEMPLATE_NC is None and WAVENUMBERS is None. Provide 14 wavenumbers (1/m).\")\n",
    "    k = np.asarray(wavenumbers, dtype=\"f8\")\n",
    "    if k.size != 14:\n",
    "        raise ValueError(f\"WAVENUMBERS length must be 14, got {k.size}\")\n",
    "    return k\n",
    "\n",
    "\n",
    "def fit_exp_modes(z, prof_tz, k, zmax=100.0, ridge_lam=0.0):\n",
    "    \"\"\"\n",
    "    Fit prof(z,t) ≈ sum_i c_i(t) * exp(-2*k_i*z), using z<=zmax.\n",
    "    Return c(t,i) shape (Nt,14).\n",
    "    \"\"\"\n",
    "    z = np.asarray(z, dtype=\"f8\")\n",
    "    prof = np.asarray(prof_tz, dtype=\"f8\")\n",
    "    k = np.asarray(k, dtype=\"f8\")\n",
    "\n",
    "    if prof.ndim != 2:\n",
    "        raise ValueError(f\"profile must be 2D (Nt,Nz). Got {prof.shape}\")\n",
    "    Nt, Nz = prof.shape\n",
    "    if Nz != z.size:\n",
    "        raise ValueError(f\"z size {z.size} != profile Nz {Nz}\")\n",
    "\n",
    "    m = np.isfinite(z) & (z <= zmax)\n",
    "    zfit = z[m]\n",
    "    if zfit.size < 14:\n",
    "        raise ValueError(f\"Too few z points <= {zmax}m: {zfit.size} (<14)\")\n",
    "\n",
    "    A = np.exp(-2.0 * zfit[:, None] * k[None, :])  # (Nzfit,14)\n",
    "\n",
    "    coeff = np.full((Nt, 14), np.nan, dtype=\"f8\")\n",
    "\n",
    "    for it in range(Nt):\n",
    "        y = prof[it, m]\n",
    "        good = np.isfinite(y)\n",
    "        if good.sum() < 14:\n",
    "            continue\n",
    "        Ag = A[good, :]\n",
    "        yg = y[good]\n",
    "\n",
    "        M = Ag.T @ Ag\n",
    "        if ridge_lam > 0:\n",
    "            M = M + ridge_lam * np.eye(14)\n",
    "        rhs = Ag.T @ yg\n",
    "        coeff[it, :] = np.linalg.solve(M, rhs)\n",
    "\n",
    "    return coeff\n",
    "\n",
    "\n",
    "def interp_1d(x_old, y_old, x_new):\n",
    "    \"\"\"\n",
    "    1D linear interpolation with NaN-safe handling.\n",
    "    x_old, x_new in same units (minutes here).\n",
    "    \"\"\"\n",
    "    x_old = np.asarray(x_old, dtype=\"f8\")\n",
    "    y_old = np.asarray(y_old, dtype=\"f8\")\n",
    "    x_new = np.asarray(x_new, dtype=\"f8\")\n",
    "\n",
    "    m = np.isfinite(x_old) & np.isfinite(y_old)\n",
    "    if m.sum() < 2:\n",
    "        return np.full_like(x_new, np.nan, dtype=\"f8\")\n",
    "\n",
    "    xo = x_old[m]\n",
    "    yo = y_old[m]\n",
    "    idx = np.argsort(xo)\n",
    "    xo = xo[idx]\n",
    "    yo = yo[idx]\n",
    "\n",
    "    return np.interp(x_new, xo, yo)\n",
    "\n",
    "\n",
    "def write_forcing_nc(out_path, t_min_i8, k,\n",
    "                     taux_t, tauy_t, usx_t14, usy_t14,\n",
    "                     description=\"Stokes drift for location XXX\"):\n",
    "\n",
    "    with Dataset(out_path, \"w\", format=\"NETCDF4\") as nc:\n",
    "        nc.createDimension(\"Time\", None)\n",
    "        nc.createDimension(\"Lat\", 2)\n",
    "        nc.createDimension(\"Lon\", 2)\n",
    "        nc.createDimension(\"wavenumber\", 14)\n",
    "\n",
    "        vtime = nc.createVariable(\"Time\", \"i8\", (\"Time\",))\n",
    "        vtime.units = TIME_UNITS\n",
    "        vtime.calendar = TIME_CAL\n",
    "        vtime[:] = t_min_i8\n",
    "\n",
    "        vwn = nc.createVariable(\"wavenumber\", \"f8\", (\"wavenumber\",), fill_value=np.nan)\n",
    "        vwn[:] = k\n",
    "\n",
    "        vlat = nc.createVariable(\"Lat\", \"f8\", (\"Lat\",), fill_value=np.nan)\n",
    "        vlon = nc.createVariable(\"Lon\", \"f8\", (\"Lon\",), fill_value=np.nan)\n",
    "        vlat[:] = LAT_2\n",
    "        vlon[:] = LON_2\n",
    "\n",
    "        vtaux = nc.createVariable(\"Taux\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=np.nan)\n",
    "        vtauy = nc.createVariable(\"Tauy\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=np.nan)\n",
    "        vtaux[:, :, :] = taux_t[:, None, None]\n",
    "        vtauy[:, :, :] = tauy_t[:, None, None]\n",
    "\n",
    "        for i in range(14):\n",
    "            vx = nc.createVariable(f\"Usx{i+1}\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=FILL_US)\n",
    "            vy = nc.createVariable(f\"Usy{i+1}\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=FILL_US)\n",
    "            vx[:, :, :] = usx_t14[:, i][:, None, None]\n",
    "            vy[:, :, :] = usy_t14[:, i][:, None, None]\n",
    "\n",
    "        nc.description = description\n",
    "\n",
    "\n",
    "def main():\n",
    "    k = get_k(TEMPLATE_NC, WAVENUMBERS)\n",
    "\n",
    "    for case_id in CASE_LIST:\n",
    "        print(f\"\\n=== {case_id} ===\")\n",
    "        t_sec, z, Us, Vs, tau13l, tau23l = load_les_mat(case_id, LES_DIR)\n",
    "\n",
    "        # LES original time in minutes (since 2011-04-01 00:00:00)\n",
    "        t_min_les = t_sec / 60.0\n",
    "\n",
    "        # stresses (your convention)\n",
    "        taux_les = tau13l[:, 0] * 1000.0\n",
    "        tauy_les = tau23l[:, 0] * 1000.0\n",
    "\n",
    "        # 14-band fit on LES native times\n",
    "        usx14_les = fit_exp_modes(z, Us, k, zmax=ZMAX_FIT, ridge_lam=RIDGE_LAM)\n",
    "        usy14_les = fit_exp_modes(z, Vs, k, zmax=ZMAX_FIT, ridge_lam=RIDGE_LAM)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # OUTPUT time grid: regular every 10 min, STARTING FROM 0\n",
    "        # ------------------------------------------------------------\n",
    "        DUR_MIN = 3 * 24 * 60          # 4320 minutes\n",
    "        t_min_i8 = np.arange(0, DUR_MIN + DT_MIN_OUT, DT_MIN_OUT, dtype=\"i8\")  # 0..4320\n",
    "        if t_min_i8.size != 433:\n",
    "            raise RuntimeError(f\"Expected 433 time steps, got {t_min_i8.size}. Check DT_MIN_OUT.\")\n",
    "        t_min_out = t_min_i8.astype(\"f8\")\n",
    "\n",
    "        # interpolate tau to 10-min grid\n",
    "        taux = interp_1d(t_min_les, taux_les, t_min_out)\n",
    "        tauy = interp_1d(t_min_les, tauy_les, t_min_out)\n",
    "\n",
    "        # interpolate 14-band coefficients to 10-min grid\n",
    "        usx14 = np.zeros((t_min_i8.size, 14), dtype=\"f8\")\n",
    "        usy14 = np.zeros((t_min_i8.size, 14), dtype=\"f8\")\n",
    "        for jj in range(14):\n",
    "            usx14[:, jj] = interp_1d(t_min_les, usx14_les[:, jj], t_min_out)\n",
    "            usy14[:, jj] = interp_1d(t_min_les, usy14_les[:, jj], t_min_out)\n",
    "\n",
    "        out_nc = os.path.join(OUT_DIR, f\"05_{case_id}.nc\")\n",
    "        write_forcing_nc(\n",
    "            out_nc, t_min_i8, k,\n",
    "            taux, tauy, usx14, usy14,\n",
    "            description=f\"Stokes drift + wind stress forcing from LES {case_id}\"\n",
    "        )\n",
    "        print(\"Wrote:\", out_nc)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cfc6b-c97d-4267-bff9-8112df9a4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# ============================================================\n",
    "#bulk LES fit\n",
    "# Build Stokes-drift-bands + wind stress forcing NetCDF\n",
    "#   - Input structure: 10mps, mixed layer depth: 10m\n",
    "#       LES_DIR/\n",
    "#          021/LESout.mat\n",
    "#          031/LESout.mat\n",
    "#          ...\n",
    "#   - Output: one NetCDF per case\n",
    "#\n",
    "# CHANGE in this version:\n",
    "#   - Output time axis is REGULAR every 10 minutes, starting from 0 minutes\n",
    "#   - All fields are interpolated onto that 10-min grid\n",
    "#\n",
    "# IMPORTANT CHANGE (your request):\n",
    "#   - Fit uses LAYER-MEAN basis consistent with LES z being cell centers (bulk)\n",
    "#     instead of point-value exp(-2*k*z_center).\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------\n",
    "# USER SETTINGS\n",
    "# -----------------------\n",
    "LES_DIR = \"/archive/bgr/Datasets/LES/MoreHurr/TS10_ML10/LT/\"\n",
    "OUT_DIR = \"/archive/Qian.Xiao/Qian.Xiao/MOM6_kappa_ePBL/ice/10m_Forcing/\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "CASE_LIST = [\n",
    "    \"021\",\"031\",\"036\",\"038\",\"040\",\"042\",\"044\",\"046\",\"048\",\"050\",\n",
    "    \"051\",\"053\",\"055\",\"057\",\"059\",\"061\",\"063\",\"065\",\"071\",\"081\",\n",
    "]\n",
    "\n",
    "# 读 wavenumber（推荐用你已有的14-band模板 forcing 文件）\n",
    "TEMPLATE_NC = None  # e.g. \"/path/to/template_14bands.nc\"\n",
    "WAVENUMBERS = [0.006, 0.01 , 0.02 , 0.04 , 0.06 , 0.08 , 0.1  , 0.2  , 0.4  , 0.6  ,\n",
    "               0.8  , 1.   , 2.   , 4. ]  # length 14\n",
    "\n",
    "# Lat/Lon 必须 -10,10\n",
    "LAT_2 = np.array([-10.0, 10.0], dtype=\"f8\")\n",
    "LON_2 = np.array([-10.0, 10.0], dtype=\"f8\")\n",
    "\n",
    "# Fit controls\n",
    "ZMAX_FIT  = 100.0       # meters (top 100m)\n",
    "RIDGE_LAM = 1e-8        # small ridge\n",
    "FILL_US   = 1.0e32      # fillvalue for Usx/Usy\n",
    "\n",
    "TIME_UNITS = \"minutes since 2011-04-01 00:00:00\"\n",
    "TIME_CAL   = \"gregorian\"\n",
    "\n",
    "# Output time grid control\n",
    "DT_MIN_OUT = 10  # minutes, fixed output interval\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# helpers\n",
    "# -----------------------\n",
    "def load_les_mat(case_id: str, root_dir: str):\n",
    "    \"\"\"Load LESout.mat from root_dir/<case_id>/LESout.mat\"\"\"\n",
    "    f = os.path.join(root_dir, case_id, \"LESout.mat\")\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f)\n",
    "    m = sio.loadmat(f)\n",
    "\n",
    "    t_sec = np.asarray(m[\"t\"]).squeeze().astype(\"f8\")    # seconds\n",
    "    z     = np.asarray(m[\"z\"]).T.squeeze().astype(\"f8\")  # meters, positive down (CELL CENTERS)\n",
    "\n",
    "    Us = np.asarray(m[\"Us\"]).astype(\"f8\")                # (Nt, Nz) layer-mean at z-centers\n",
    "    Vs = np.asarray(m[\"Vs\"]).astype(\"f8\")                # (Nt, Nz)\n",
    "\n",
    "    tau13l = np.asarray(m[\"tau13l\"]).astype(\"f8\")        # (Nt, Nz?) we use [:,0]\n",
    "    tau23l = np.asarray(m[\"tau23l\"]).astype(\"f8\")\n",
    "\n",
    "    return t_sec, z, Us, Vs, tau13l, tau23l\n",
    "\n",
    "\n",
    "def get_k(template_nc, wavenumbers):\n",
    "    if template_nc is not None and os.path.exists(template_nc):\n",
    "        with Dataset(template_nc, \"r\") as nc:\n",
    "            k = np.asarray(nc.variables[\"wavenumber\"][:], dtype=\"f8\")\n",
    "        if k.size != 14:\n",
    "            raise ValueError(f\"Template wavenumber size != 14: {k.size}\")\n",
    "        return k\n",
    "\n",
    "    if wavenumbers is None:\n",
    "        raise ValueError(\"TEMPLATE_NC is None and WAVENUMBERS is None. Provide 14 wavenumbers (1/m).\")\n",
    "    k = np.asarray(wavenumbers, dtype=\"f8\")\n",
    "    if k.size != 14:\n",
    "        raise ValueError(f\"WAVENUMBERS length must be 14, got {k.size}\")\n",
    "    return k\n",
    "\n",
    "\n",
    "def centers_to_interfaces(zc):\n",
    "    \"\"\"\n",
    "    Convert cell-center depths to interfaces.\n",
    "    Assumes top boundary at z=0 and roughly monotonic spacing.\n",
    "    zc: (Nz,) positive down\n",
    "    Returns:\n",
    "      zi: (Nz+1,) interfaces with zi[0]=0\n",
    "      dz: (Nz,) layer thickness\n",
    "    \"\"\"\n",
    "    zc = np.asarray(zc, dtype=\"f8\").squeeze()\n",
    "    if zc.ndim != 1:\n",
    "        raise ValueError(f\"zc must be 1D, got shape {zc.shape}\")\n",
    "    if zc.size < 2:\n",
    "        raise ValueError(\"Need at least 2 z levels to infer interfaces.\")\n",
    "    if np.any(np.diff(zc) <= 0):\n",
    "        # if not strictly increasing, sort (defensive)\n",
    "        order = np.argsort(zc)\n",
    "        zc = zc[order]\n",
    "\n",
    "    Nz = zc.size\n",
    "    zi = np.empty(Nz + 1, dtype=\"f8\")\n",
    "    zi[0] = 0.0\n",
    "    zi[1:-1] = 0.5 * (zc[:-1] + zc[1:])\n",
    "    # bottom interface extrapolated using last spacing\n",
    "    zi[-1] = zc[-1] + 0.5 * (zc[-1] - zc[-2])\n",
    "\n",
    "    dz = zi[1:] - zi[:-1]\n",
    "    if np.any(dz <= 0):\n",
    "        raise ValueError(\"Non-positive layer thickness inferred; check z centers.\")\n",
    "    return zi, dz\n",
    "\n",
    "\n",
    "def layermean_exp_basis(zi, k):\n",
    "    \"\"\"\n",
    "    Build layer-mean basis for exp(-2*k*z) over each layer.\n",
    "    For layer [z_top, z_bot]:\n",
    "      <exp(-2*k*z)> = (exp(-2*k*z_top) - exp(-2*k*z_bot)) / (2*k*dz)\n",
    "    zi: (Nz+1,) interfaces\n",
    "    k:  (Nb,)\n",
    "    Returns Abar: (Nz, Nb)\n",
    "    \"\"\"\n",
    "    zi = np.asarray(zi, dtype=\"f8\")\n",
    "    k  = np.asarray(k,  dtype=\"f8\")\n",
    "\n",
    "    ztop = zi[:-1][:, None]\n",
    "    zbot = zi[1:][:, None]\n",
    "    dz   = (zbot - ztop)\n",
    "\n",
    "    # avoid divide by 0 for any pathological k (shouldn't happen here)\n",
    "    kk = np.where(np.abs(k) > 0, k, np.nan)\n",
    "    Abar = (np.exp(-2.0 * kk[None, :] * ztop) - np.exp(-2.0 * kk[None, :] * zbot)) / (2.0 * kk[None, :] * dz)\n",
    "    return Abar\n",
    "\n",
    "\n",
    "def fit_exp_modes(zc, prof_tz, k, zmax=100.0, ridge_lam=0.0):\n",
    "    \"\"\"\n",
    "    LAYER-MEAN fit (consistent with LES z being cell centers / bulk):\n",
    "      prof_layermean(z,t) ≈ sum_i c_i(t) * <exp(-2*k_i*z)>_layer\n",
    "    where < > is layer-average over each cell.\n",
    "\n",
    "    Inputs:\n",
    "      zc: cell-center depths (Nz,)\n",
    "      prof_tz: (Nt, Nz) layer-mean profile (Us or Vs)\n",
    "      k: (14,)\n",
    "    Returns:\n",
    "      coeff: (Nt, 14) interpreted as surface amplitudes for each band.\n",
    "    \"\"\"\n",
    "    zc = np.asarray(zc, dtype=\"f8\").squeeze()\n",
    "    prof = np.asarray(prof_tz, dtype=\"f8\")\n",
    "    k = np.asarray(k, dtype=\"f8\").squeeze()\n",
    "\n",
    "    if prof.ndim != 2:\n",
    "        raise ValueError(f\"profile must be 2D (Nt,Nz). Got {prof.shape}\")\n",
    "    Nt, Nz = prof.shape\n",
    "    if Nz != zc.size:\n",
    "        raise ValueError(f\"z size {zc.size} != profile Nz {Nz}\")\n",
    "\n",
    "    # build interfaces and layer-mean basis\n",
    "    zi, dz = centers_to_interfaces(zc)\n",
    "    Abar_full = layermean_exp_basis(zi, k)  # (Nz,14)\n",
    "\n",
    "    # only use layers with center <= zmax\n",
    "    m = np.isfinite(zc) & (zc <= zmax)\n",
    "    if m.sum() < 14:\n",
    "        raise ValueError(f\"Too few z layers with center <= {zmax}m: {m.sum()} (<14)\")\n",
    "\n",
    "    A = Abar_full[m, :]  # (Nzfit,14)\n",
    "\n",
    "    coeff = np.full((Nt, 14), np.nan, dtype=\"f8\")\n",
    "    for it in range(Nt):\n",
    "        y = prof[it, m]\n",
    "        good = np.isfinite(y)\n",
    "        if good.sum() < 14:\n",
    "            continue\n",
    "        Ag = A[good, :]\n",
    "        yg = y[good]\n",
    "\n",
    "        M = Ag.T @ Ag\n",
    "        if ridge_lam > 0:\n",
    "            M = M + ridge_lam * np.eye(14)\n",
    "        rhs = Ag.T @ yg\n",
    "        coeff[it, :] = np.linalg.solve(M, rhs)\n",
    "\n",
    "    return coeff\n",
    "\n",
    "\n",
    "def interp_1d(x_old, y_old, x_new):\n",
    "    \"\"\"\n",
    "    1D linear interpolation with NaN-safe handling.\n",
    "    x_old, x_new in same units (minutes here).\n",
    "    \"\"\"\n",
    "    x_old = np.asarray(x_old, dtype=\"f8\")\n",
    "    y_old = np.asarray(y_old, dtype=\"f8\")\n",
    "    x_new = np.asarray(x_new, dtype=\"f8\")\n",
    "\n",
    "    m = np.isfinite(x_old) & np.isfinite(y_old)\n",
    "    if m.sum() < 2:\n",
    "        return np.full_like(x_new, np.nan, dtype=\"f8\")\n",
    "\n",
    "    xo = x_old[m]\n",
    "    yo = y_old[m]\n",
    "    idx = np.argsort(xo)\n",
    "    xo = xo[idx]\n",
    "    yo = yo[idx]\n",
    "\n",
    "    return np.interp(x_new, xo, yo)\n",
    "\n",
    "\n",
    "def write_forcing_nc(out_path, t_min_i8, k,\n",
    "                     taux_t, tauy_t, usx_t14, usy_t14,\n",
    "                     description=\"Stokes drift for location XXX\"):\n",
    "\n",
    "    with Dataset(out_path, \"w\", format=\"NETCDF4\") as nc:\n",
    "        nc.createDimension(\"Time\", None)\n",
    "        nc.createDimension(\"Lat\", 2)\n",
    "        nc.createDimension(\"Lon\", 2)\n",
    "        nc.createDimension(\"wavenumber\", 14)\n",
    "\n",
    "        vtime = nc.createVariable(\"Time\", \"i8\", (\"Time\",))\n",
    "        vtime.units = TIME_UNITS\n",
    "        vtime.calendar = TIME_CAL\n",
    "        vtime[:] = t_min_i8\n",
    "\n",
    "        vwn = nc.createVariable(\"wavenumber\", \"f8\", (\"wavenumber\",), fill_value=np.nan)\n",
    "        vwn[:] = k\n",
    "\n",
    "        vlat = nc.createVariable(\"Lat\", \"f8\", (\"Lat\",), fill_value=np.nan)\n",
    "        vlon = nc.createVariable(\"Lon\", \"f8\", (\"Lon\",), fill_value=np.nan)\n",
    "        vlat[:] = LAT_2\n",
    "        vlon[:] = LON_2\n",
    "\n",
    "        vtaux = nc.createVariable(\"Taux\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=np.nan)\n",
    "        vtauy = nc.createVariable(\"Tauy\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=np.nan)\n",
    "        vtaux[:, :, :] = taux_t[:, None, None]\n",
    "        vtauy[:, :, :] = tauy_t[:, None, None]\n",
    "\n",
    "        for i in range(14):\n",
    "            vx = nc.createVariable(f\"Usx{i+1}\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=FILL_US)\n",
    "            vy = nc.createVariable(f\"Usy{i+1}\", \"f8\", (\"Time\",\"Lat\",\"Lon\"), fill_value=FILL_US)\n",
    "            vx[:, :, :] = usx_t14[:, i][:, None, None]\n",
    "            vy[:, :, :] = usy_t14[:, i][:, None, None]\n",
    "\n",
    "        nc.description = description\n",
    "\n",
    "\n",
    "def main():\n",
    "    k = get_k(TEMPLATE_NC, WAVENUMBERS)\n",
    "\n",
    "    for case_id in CASE_LIST:\n",
    "        print(f\"\\n=== {case_id} ===\")\n",
    "        t_sec, z, Us, Vs, tau13l, tau23l = load_les_mat(case_id, LES_DIR)\n",
    "\n",
    "        # LES original time in minutes (since 2011-04-01 00:00:00)\n",
    "        t_min_les = t_sec / 60.0\n",
    "\n",
    "        # stresses (your convention)\n",
    "        taux_les = tau13l[:, 0] * 1000.0\n",
    "        tauy_les = tau23l[:, 0] * 1000.0\n",
    "\n",
    "        # 14-band fit on LES native times (LAYER-MEAN basis)\n",
    "        usx14_les = fit_exp_modes(z, Us, k, zmax=ZMAX_FIT, ridge_lam=RIDGE_LAM)\n",
    "        usy14_les = fit_exp_modes(z, Vs, k, zmax=ZMAX_FIT, ridge_lam=RIDGE_LAM)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # OUTPUT time grid: regular every 10 min, STARTING FROM 0\n",
    "        # ------------------------------------------------------------\n",
    "        DUR_MIN = 3 * 24 * 60  # 4320 minutes\n",
    "        t_min_i8 = np.arange(0, DUR_MIN + DT_MIN_OUT, DT_MIN_OUT, dtype=\"i8\")  # 0..4320\n",
    "        if t_min_i8.size != 433:\n",
    "            raise RuntimeError(f\"Expected 433 time steps, got {t_min_i8.size}. Check DT_MIN_OUT.\")\n",
    "        t_min_out = t_min_i8.astype(\"f8\")\n",
    "\n",
    "        # interpolate tau to 10-min grid\n",
    "        taux = interp_1d(t_min_les, taux_les, t_min_out)\n",
    "        tauy = interp_1d(t_min_les, tauy_les, t_min_out)\n",
    "\n",
    "        # interpolate 14-band coefficients to 10-min grid\n",
    "        usx14 = np.zeros((t_min_i8.size, 14), dtype=\"f8\")\n",
    "        usy14 = np.zeros((t_min_i8.size, 14), dtype=\"f8\")\n",
    "        for jj in range(14):\n",
    "            usx14[:, jj] = interp_1d(t_min_les, usx14_les[:, jj], t_min_out)\n",
    "            usy14[:, jj] = interp_1d(t_min_les, usy14_les[:, jj], t_min_out)\n",
    "\n",
    "        out_nc = os.path.join(OUT_DIR, f\"10_{case_id}.nc\")\n",
    "        write_forcing_nc(\n",
    "            out_nc, t_min_i8, k,\n",
    "            taux, tauy, usx14, usy14,\n",
    "            description=f\"Stokes drift + wind stress forcing from LES {case_id}\"\n",
    "        )\n",
    "        print(\"Wrote:\", out_nc)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bbf42-0458-471d-a203-62d92dbc2686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# ============================================================\n",
    "# Compare forcing NetCDF vs LES (LESout.mat)\n",
    "#   Panels: check for my own wind-wave output files 10m 5mps\n",
    "#using LES z0 as the first layer of z=0 to fit Or as z0 layer-average bulk stokes drift\n",
    "#     Row1: Taux, Tauy\n",
    "#     Row2: Usx(top cell), Usy(top cell)\n",
    "#     Row3: |Us|(top cell)\n",
    "#     Row4: profile check @ one forcing time (Usx(z), Usy(z), |Us|(z))\n",
    "#   No saving, only plt.show()\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------\n",
    "# USER SETTINGS\n",
    "# -----------------------\n",
    "FORCING_NC = \"/archive/Qian.Xiao/Qian.Xiao/MOM6_kappa_ePBL/ice/10m_Forcing/10_046.nc\"\n",
    "LES_ROOT   = \"/archive/bgr/Datasets/LES/MoreHurr/TS10_ML10/LT/\"  # contains 021/031/... and one extra subdir\n",
    "CASE_ID    = None        # None -> infer from forcing filename \"05_081.nc\" -> \"081\"\n",
    "\n",
    "IT_FORCE_CHECK = -1      # forcing time index for profile check (-1 = last)\n",
    "ZMAX_PLOT  = 240.0       # meters for profile plot\n",
    "\n",
    "# conventions\n",
    "RHO_W = 1000.0           # for LES tau*1000 like you use\n",
    "FILL_US_THRES = 1e20     # treat >1e20 as missing (forcing uses 1e32)\n",
    "\n",
    "# -----------------------\n",
    "# time helpers (avoid cftime)\n",
    "# -----------------------\n",
    "def parse_time_units(units_str: str):\n",
    "    \"\"\"\n",
    "    Parse units like: \"minutes since 2011-04-01 00:00:00\"\n",
    "    Return (base_datetime, seconds_per_unit)\n",
    "    \"\"\"\n",
    "    s = units_str.strip()\n",
    "    if \"since\" not in s:\n",
    "        raise ValueError(f\"Unrecognized time units (no 'since'): {units_str}\")\n",
    "    left, right = s.split(\"since\", 1)\n",
    "    unit = left.strip().lower()\n",
    "    base_str = right.strip()\n",
    "\n",
    "    fmts = [\"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H:%M\", \"%Y-%m-%d\"]\n",
    "    base = None\n",
    "    for fmt in fmts:\n",
    "        try:\n",
    "            base = datetime.strptime(base_str, fmt)\n",
    "            break\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if base is None:\n",
    "        base = datetime.fromisoformat(base_str)\n",
    "\n",
    "    sec_per = {\n",
    "        \"seconds\": 1.0, \"second\": 1.0, \"sec\": 1.0, \"s\": 1.0,\n",
    "        \"minutes\": 60.0, \"minute\": 60.0, \"min\": 60.0,\n",
    "        \"hours\": 3600.0, \"hour\": 3600.0, \"hr\": 3600.0, \"h\": 3600.0,\n",
    "        \"days\": 86400.0, \"day\": 86400.0, \"d\": 86400.0,\n",
    "    }\n",
    "    if unit not in sec_per:\n",
    "        raise ValueError(f\"Unsupported time unit '{unit}' in units='{units_str}'\")\n",
    "    return base, sec_per[unit]\n",
    "\n",
    "def timevals_to_datetimes(time_vals, units_str):\n",
    "    base, sec_per_unit = parse_time_units(units_str)\n",
    "    t = np.asarray(time_vals, dtype=\"f8\")\n",
    "    return np.array([base + timedelta(seconds=float(v) * sec_per_unit) for v in t], dtype=object)\n",
    "\n",
    "# -----------------------\n",
    "# path + IO helpers\n",
    "# -----------------------\n",
    "def infer_case_id_from_forcing(path_nc):\n",
    "    b = os.path.basename(path_nc)\n",
    "    stem = b.split(\".nc\")[0]          # \"05_081\"\n",
    "    parts = stem.split(\"_\")\n",
    "    if len(parts) >= 2 and parts[-1].isdigit():\n",
    "        return parts[-1]\n",
    "    return None\n",
    "\n",
    "def find_les_mat(case_id, root_dir):\n",
    "    # one extra directory layer, so recursive search\n",
    "    cdir = os.path.join(root_dir, case_id)\n",
    "    cand = sorted(glob.glob(os.path.join(cdir, \"**\", \"LESout.mat\"), recursive=True))\n",
    "    if not cand:\n",
    "        raise FileNotFoundError(f\"Cannot find LESout.mat under: {cdir} (recursive)\")\n",
    "    return cand[0]\n",
    "\n",
    "def load_les(les_mat_path):\n",
    "    m = sio.loadmat(les_mat_path)\n",
    "    t_sec = np.asarray(m[\"t\"]).squeeze().astype(\"f8\")       # seconds since base\n",
    "    z     = np.asarray(m[\"z\"]).squeeze().astype(\"f8\")       # meters, positive down\n",
    "\n",
    "    Us    = np.asarray(m[\"Us\"]).astype(\"f8\")                # (Nt,Nz) or (Nz,Nt)\n",
    "    Vs    = np.asarray(m[\"Vs\"]).astype(\"f8\")\n",
    "    if Us.shape[0] != t_sec.size and Us.shape[1] == t_sec.size:\n",
    "        Us = Us.T\n",
    "        Vs = Vs.T\n",
    "\n",
    "    # tau from LES (your convention)\n",
    "    tau13l = np.asarray(m[\"tau13l\"]).astype(\"f8\")           # (Nt,Nz?) or (Nz,Nt)\n",
    "    tau23l = np.asarray(m[\"tau23l\"]).astype(\"f8\")\n",
    "    if tau13l.shape[0] != t_sec.size and tau13l.shape[1] == t_sec.size:\n",
    "        tau13l = tau13l.T\n",
    "        tau23l = tau23l.T\n",
    "    taux = tau13l[:, 0] * RHO_W\n",
    "    tauy = tau23l[:, 0] * RHO_W\n",
    "\n",
    "    return t_sec, z, Us, Vs, taux, tauy\n",
    "\n",
    "def load_forcing(nc_path):\n",
    "    with Dataset(nc_path, \"r\") as nc:\n",
    "        t = np.asarray(nc.variables[\"Time\"][:], dtype=\"f8\")  # minutes since base (stored as int64)\n",
    "        tunits = nc.variables[\"Time\"].units\n",
    "        k = np.asarray(nc.variables[\"wavenumber\"][:], dtype=\"f8\")  # (14,)\n",
    "\n",
    "        # tau in forcing\n",
    "        taux = np.asarray(nc.variables[\"Taux\"][:, 0, 0], dtype=\"f8\")\n",
    "        tauy = np.asarray(nc.variables[\"Tauy\"][:, 0, 0], dtype=\"f8\")\n",
    "\n",
    "        # 14 bands\n",
    "        Nt = t.size\n",
    "        Usx14 = np.zeros((Nt, 14), dtype=\"f8\")\n",
    "        Usy14 = np.zeros((Nt, 14), dtype=\"f8\")\n",
    "        for i in range(14):\n",
    "            vx = np.asarray(nc.variables[f\"Usx{i+1}\"][:, 0, 0], dtype=\"f8\")\n",
    "            vy = np.asarray(nc.variables[f\"Usy{i+1}\"][:, 0, 0], dtype=\"f8\")\n",
    "            vx = np.where(np.abs(vx) > FILL_US_THRES, np.nan, vx)\n",
    "            vy = np.where(np.abs(vy) > FILL_US_THRES, np.nan, vy)\n",
    "            Usx14[:, i] = vx\n",
    "            Usy14[:, i] = vy\n",
    "\n",
    "    return t, tunits, k, taux, tauy, Usx14, Usy14\n",
    "\n",
    "# -----------------------\n",
    "# reconstruction helpers\n",
    "# -----------------------\n",
    "def recon_from_bands_at_z(Us14_ti, k, z):\n",
    "    \"\"\"recon(z,t) = sum_i Us_i(t) * exp(-2*k_i*z)\"\"\"\n",
    "    z = float(z)\n",
    "    w = np.exp(-2.0 * k[None, :] * z)  # (1,14)\n",
    "    return np.nansum(Us14_ti * w, axis=1)\n",
    "\n",
    "def recon_profile_from_bands(Us14_i, k, zvec):\n",
    "    \"\"\"single-time profile\"\"\"\n",
    "    zvec = np.asarray(zvec, dtype=\"f8\")\n",
    "    A = np.exp(-2.0 * zvec[:, None] * k[None, :])  # (Nz,14)\n",
    "    return np.nansum(A * Us14_i[None, :], axis=1)\n",
    "\n",
    "# -----------------------\n",
    "# main\n",
    "# -----------------------\n",
    "def main():\n",
    "    case_id = CASE_ID or infer_case_id_from_forcing(FORCING_NC)\n",
    "    if case_id is None:\n",
    "        raise ValueError(\"Cannot infer CASE_ID from forcing filename; set CASE_ID explicitly.\")\n",
    "    les_mat = find_les_mat(case_id, LES_ROOT)\n",
    "\n",
    "    print(\"FORCING:\", FORCING_NC)\n",
    "    print(\"LES MAT :\", les_mat)\n",
    "\n",
    "    # Load\n",
    "    tF_min, tF_units, k, tauxF, tauyF, Usx14, Usy14 = load_forcing(FORCING_NC)\n",
    "    tL_sec, zL, UsL, VsL, tauxL, tauyL = load_les(les_mat)\n",
    "\n",
    "    # Absolute datetime axes\n",
    "    tF_dt = timevals_to_datetimes(tF_min, tF_units)\n",
    "    base_dt, _ = parse_time_units(tF_units)  # should be 2011-04-01 00:00:00\n",
    "    tL_dt = np.array([base_dt + timedelta(seconds=float(s)) for s in tL_sec], dtype=object)\n",
    "\n",
    "    # top cell depth (LES)\n",
    "    z0 = float(zL[0])\n",
    "\n",
    "    # \"surface/top cell\" Stokes drift series\n",
    "    UsxF_top = recon_from_bands_at_z(Usx14, k, z0)\n",
    "    UsyF_top = recon_from_bands_at_z(Usy14, k, z0)\n",
    "    absF_top = np.sqrt(UsxF_top**2 + UsyF_top**2)\n",
    "\n",
    "    UsxL_top = UsL[:, 0]\n",
    "    UsyL_top = VsL[:, 0]\n",
    "    absL_top = np.sqrt(UsxL_top**2 + UsyL_top**2)\n",
    "\n",
    "    # profile check at forcing index\n",
    "    itF = IT_FORCE_CHECK if IT_FORCE_CHECK >= 0 else (len(tF_min) + IT_FORCE_CHECK)\n",
    "    itF = int(np.clip(itF, 0, len(tF_min)-1))\n",
    "\n",
    "    # nearest LES time to forcing time\n",
    "    tF_here_min = float(tF_min[itF])\n",
    "    tL_min = tL_sec / 60.0\n",
    "    itL = int(np.argmin(np.abs(tL_min - tF_here_min)))\n",
    "    dt_min = float(tL_min[itL] - tF_here_min)\n",
    "\n",
    "    print(f\"[profile] forcing it={itF}, t={tF_dt[itF]}\")\n",
    "    print(f\"[profile] LES nearest it={itL}, t={tL_dt[itL]}, Δt={dt_min:+.2f} min\")\n",
    "\n",
    "    zmask = zL <= ZMAX_PLOT\n",
    "    zP = zL[zmask]\n",
    "\n",
    "    UsxF_prof = recon_profile_from_bands(Usx14[itF, :], k, zP)\n",
    "    UsyF_prof = recon_profile_from_bands(Usy14[itF, :], k, zP)\n",
    "    absF_prof = np.sqrt(UsxF_prof**2 + UsyF_prof**2)\n",
    "\n",
    "    UsxL_prof = UsL[itL, zmask]\n",
    "    UsyL_prof = VsL[itL, zmask]\n",
    "    absL_prof = np.sqrt(UsxL_prof**2 + UsyL_prof**2)\n",
    "\n",
    "    # -----------------------\n",
    "    # PLOT (like your screenshot layout)\n",
    "    # -----------------------\n",
    "    fig = plt.figure(figsize=(13.5, 11.5))\n",
    "    gs = fig.add_gridspec(nrows=4, ncols=6, height_ratios=[1.0, 1.0, 1.0, 1.25],\n",
    "                          hspace=0.55, wspace=0.65)\n",
    "\n",
    "    ax_tx  = fig.add_subplot(gs[0, 0:3])\n",
    "    ax_ty  = fig.add_subplot(gs[0, 3:6])\n",
    "    ax_ux  = fig.add_subplot(gs[1, 0:3])\n",
    "    ax_uy  = fig.add_subplot(gs[1, 3:6])\n",
    "    ax_abs = fig.add_subplot(gs[2, :])\n",
    "\n",
    "    ax_px  = fig.add_subplot(gs[3, 0:2])\n",
    "    ax_py  = fig.add_subplot(gs[3, 2:4])\n",
    "    ax_pa  = fig.add_subplot(gs[3, 4:6])\n",
    "\n",
    "    fmt = mdates.DateFormatter(\"%m-%d %H:%M\")\n",
    "    for ax in (ax_tx, ax_ty, ax_ux, ax_uy, ax_abs):\n",
    "        ax.xaxis.set_major_formatter(fmt)\n",
    "        ax.tick_params(axis=\"x\", rotation=25)\n",
    "\n",
    "    # --- tau time series\n",
    "    ax_tx.plot(tF_dt, tauxF, label=\"forcing\")\n",
    "    ax_tx.plot(tL_dt, tauxL, \"--\", label=\"LES\")\n",
    "    ax_tx.set_title(\"Taux\")\n",
    "    ax_tx.legend(frameon=True)\n",
    "\n",
    "    ax_ty.plot(tF_dt, tauyF, label=\"forcing\")\n",
    "    ax_ty.plot(tL_dt, tauyL, \"--\", label=\"LES\")\n",
    "    ax_ty.set_title(\"Tauy\")\n",
    "    ax_ty.legend(frameon=True)\n",
    "\n",
    "    # --- Us top-cell series\n",
    "    ax_ux.plot(tF_dt, UsxF_top, label=\"forcing\")\n",
    "    ax_ux.plot(tL_dt, UsxL_top, \"--\", label=\"LES\")\n",
    "    ax_ux.set_title(\"Us_x (surface/top cell)\")\n",
    "    ax_ux.legend(frameon=True)\n",
    "\n",
    "    ax_uy.plot(tF_dt, UsyF_top, label=\"forcing\")\n",
    "    ax_uy.plot(tL_dt, UsyL_top, \"--\", label=\"LES\")\n",
    "    ax_uy.set_title(\"Us_y (surface/top cell)\")\n",
    "    ax_uy.legend(frameon=True)\n",
    "\n",
    "    ax_abs.plot(tF_dt, absF_top, label=\"forcing |Us|\")\n",
    "    ax_abs.plot(tL_dt, absL_top, \"--\", label=\"LES |Us|\")\n",
    "    ax_abs.set_title(\"|Us| comparison\")\n",
    "    ax_abs.legend(frameon=True)\n",
    "\n",
    "    # profile check header text\n",
    "    fig.text(\n",
    "        0.5, 0.275,\n",
    "        f\"Profile check @ forcing time {tF_dt[itF]} (LES nearest, Δt={dt_min:+.2f} min)\",\n",
    "        ha=\"center\", va=\"center\", fontsize=12\n",
    "    )\n",
    "\n",
    "    # profiles\n",
    "    ax_px.plot(UsxF_prof, zP, label=\"forcing\")\n",
    "    ax_px.plot(UsxL_prof, zP, \"--\", label=\"LES\")\n",
    "    ax_px.set_title(\"Usx(z)\")\n",
    "    ax_px.set_ylabel(\"z (m, positive down)\")\n",
    "    ax_px.grid(True, alpha=0.25)\n",
    "    ax_px.invert_yaxis()\n",
    "\n",
    "    ax_py.plot(UsyF_prof, zP, label=\"forcing\")\n",
    "    ax_py.plot(UsyL_prof, zP, \"--\", label=\"LES\")\n",
    "    ax_py.set_title(\"Usy(z)\")\n",
    "    ax_py.grid(True, alpha=0.25)\n",
    "    ax_py.invert_yaxis()\n",
    "\n",
    "    ax_pa.plot(absF_prof, zP, label=\"forcing\")\n",
    "    ax_pa.plot(absL_prof, zP, \"--\", label=\"LES\")\n",
    "    ax_pa.set_title(\"|Us|(z)\")\n",
    "    ax_pa.grid(True, alpha=0.25)\n",
    "    ax_pa.invert_yaxis()\n",
    "    ax_pa.legend(frameon=True)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c97963-7f61-4b10-89e7-2ddefc53d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime as dt\n",
    "from netCDF4 import num2date\n",
    "\n",
    "# =========================\n",
    "# USER SETTINGS check for SCM_windwaveInputfiles.ipynb wind-wave input file VS LES data 5mps 32m MLD\n",
    "# =========================\n",
    "FORCING_NC= f\"/archive/Qian.Xiao/Qian.Xiao/MOM6_kappa_ePBL/ice/10m_Forcing/Hurr05_046.nc\"\n",
    "LES_MAT    = f\"/archive/bgr/Datasets/LES/Hurr/LES_HUR/TC021_PROF.mat\"   # <- 改成你的 LESout.mat 路径\n",
    "\n",
    "CASE=\"1\"\n",
    "\n",
    "NBAND = 14\n",
    "LAT_IDX = 0\n",
    "LON_IDX = 0\n",
    "\n",
    "N_FORC_MAX = 100           # 你说前100就够\n",
    "PROFILE_FORC_IT = -1       # forcing 选哪个时刻做 profile check（-1=最后一个）\n",
    "\n",
    "LES_TAUX_SCALE = 1000.0    # 你说 tau*1000\n",
    "LES_TAUY_SCALE = 1000.0\n",
    "\n",
    "# =========================\n",
    "# helpers\n",
    "# =========================\n",
    "def parse_units_base_datetime(units_str: str) -> dt.datetime:\n",
    "    m = re.search(r\"since\\s+(.+)$\", units_str.strip())\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse base datetime from units: {units_str}\")\n",
    "    base = m.group(1).strip()\n",
    "    for fmt in (\"%Y-%m-%d %H:%M:%S\", \"%Y-%m-%d %H:%M\", \"%Y-%m-%dT%H:%M:%S\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            return dt.datetime.strptime(base, fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    try:\n",
    "        return dt.datetime.fromisoformat(base.replace(\"Z\",\"\"))\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Cannot parse base datetime '{base}' from units '{units_str}': {e}\")\n",
    "\n",
    "def to_py_datetime_list(tlist):\n",
    "    \"\"\"\n",
    "    Convert cftime datetimes (or numpy datetime64) to python datetime.datetime.\n",
    "    Matplotlib needs python datetime or numpy datetime64.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for t in tlist:\n",
    "        # already python datetime\n",
    "        if isinstance(t, dt.datetime):\n",
    "            out.append(t)\n",
    "            continue\n",
    "\n",
    "        # numpy datetime64\n",
    "        if isinstance(t, np.datetime64):\n",
    "            # convert to python datetime (naive)\n",
    "            ts = (t - np.datetime64(\"1970-01-01T00:00:00\")) / np.timedelta64(1, \"s\")\n",
    "            out.append(dt.datetime(1970,1,1) + dt.timedelta(seconds=float(ts)))\n",
    "            continue\n",
    "\n",
    "        # cftime objects: have year/month/day/hour/minute/second\n",
    "        # second may be float; handle microseconds safely\n",
    "        sec = float(getattr(t, \"second\"))\n",
    "        isec = int(sec)\n",
    "        usec = int(round((sec - isec) * 1e6))\n",
    "        out.append(dt.datetime(int(t.year), int(t.month), int(t.day),\n",
    "                               int(getattr(t, \"hour\", 0)),\n",
    "                               int(getattr(t, \"minute\", 0)),\n",
    "                               isec, usec))\n",
    "    return out\n",
    "\n",
    "def clean_fill(x):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = np.where(np.abs(x) > 1e20, np.nan, x)  # 处理 1e32 fill\n",
    "    return x\n",
    "\n",
    "def pick_point(da, lat_i=0, lon_i=0, nmax=None):\n",
    "    x = da.isel(Lat=lat_i, Lon=lon_i).values\n",
    "    if nmax is not None:\n",
    "        x = x[:nmax]\n",
    "    return clean_fill(x)\n",
    "\n",
    "def forcing_profile_from_bands(usx_band, usy_band, k, z):\n",
    "    \"\"\"\n",
    "    Us(z) = Σ Us0_i * exp(-2*k_i*z)\n",
    "    k: 1/m, z: m (positive down)\n",
    "    \"\"\"\n",
    "    z = np.asarray(z, dtype=float)\n",
    "    k = np.asarray(k, dtype=float)\n",
    "    decay = np.exp(-2.0 * k[:, None] * z[None, :])   # (nband, nz)\n",
    "    usx_z = np.nansum(usx_band[:, None] * decay, axis=0)\n",
    "    usy_z = np.nansum(usy_band[:, None] * decay, axis=0)\n",
    "    us_z  = np.sqrt(usx_z**2 + usy_z**2)\n",
    "    return usx_z, usy_z, us_z\n",
    "\n",
    "def nearest_idx_datetime(dts, dt_target):\n",
    "    sec = np.array([(x - dt_target).total_seconds() for x in dts], dtype=float)\n",
    "    return int(np.argmin(np.abs(sec)))\n",
    "\n",
    "def guess_les_time_seconds(t_array):\n",
    "    \"\"\"\n",
    "    你如果某些 LES t 不是秒，这里自动猜一下（尽量不误判）：\n",
    "    - max < 10   -> days\n",
    "    - max < 300  -> hours\n",
    "    - else       -> seconds\n",
    "    \"\"\"\n",
    "    tmax = float(np.nanmax(t_array))\n",
    "    if tmax < 10:\n",
    "        return t_array * 86400.0\n",
    "    if tmax < 300:\n",
    "        return t_array * 3600.0\n",
    "    return t_array\n",
    "\n",
    "# =========================\n",
    "# main\n",
    "# =========================\n",
    "if not os.path.exists(FORCING_NC):\n",
    "    raise FileNotFoundError(FORCING_NC)\n",
    "if not os.path.exists(LES_MAT):\n",
    "    raise FileNotFoundError(LES_MAT)\n",
    "\n",
    "# ---- read forcing ----\n",
    "dsF = xr.open_dataset(FORCING_NC, decode_times=False)\n",
    "\n",
    "units = dsF[\"Time\"].attrs.get(\"units\", \"minutes since 2011-04-01 00:00:00\")\n",
    "cal   = dsF[\"Time\"].attrs.get(\"calendar\", \"gregorian\")\n",
    "\n",
    "tF_raw = np.asarray(dsF[\"Time\"].values, dtype=float)\n",
    "if N_FORC_MAX is not None:\n",
    "    tF_raw = tF_raw[:N_FORC_MAX]\n",
    "\n",
    "# 关键：num2date -> cftime；再转 python datetime\n",
    "try:\n",
    "    tF_tmp = num2date(tF_raw, units=units, calendar=cal,\n",
    "                      only_use_cftime_datetimes=False, only_use_python_datetimes=True)\n",
    "except TypeError:\n",
    "    # 旧版 netCDF4 没这些参数\n",
    "    tF_tmp = num2date(tF_raw, units=units, calendar=cal)\n",
    "tF_dt = to_py_datetime_list(tF_tmp)\n",
    "\n",
    "tauxF = pick_point(dsF[\"Taux\"], LAT_IDX, LON_IDX, N_FORC_MAX)\n",
    "tauyF = pick_point(dsF[\"Tauy\"], LAT_IDX, LON_IDX, N_FORC_MAX)\n",
    "\n",
    "k = np.asarray(dsF[\"wavenumber\"].values, dtype=float)[:NBAND]  # 按 1/m 用\n",
    "\n",
    "usx_bands = np.zeros((NBAND, len(tF_dt)), dtype=float)\n",
    "usy_bands = np.zeros((NBAND, len(tF_dt)), dtype=float)\n",
    "for i in range(1, NBAND + 1):\n",
    "    usx_bands[i-1, :] = pick_point(dsF[f\"Usx{i}\"], LAT_IDX, LON_IDX, N_FORC_MAX)\n",
    "    usy_bands[i-1, :] = pick_point(dsF[f\"Usy{i}\"], LAT_IDX, LON_IDX, N_FORC_MAX)\n",
    "\n",
    "dsF.close()\n",
    "\n",
    "usx0F = np.nansum(usx_bands, axis=0)\n",
    "usy0F = np.nansum(usy_bands, axis=0)\n",
    "us0F  = np.sqrt(usx0F**2 + usy0F**2)\n",
    "\n",
    "# ---- read LES ----\n",
    "M = sio.loadmat(LES_MAT)\n",
    "\n",
    "tL_raw = np.asarray(M[\"t\"]).squeeze().astype(float)\n",
    "tL_sec = guess_les_time_seconds(tL_raw)   # 自动把 days/hours 也转成 sec（如果本来就是 sec 不变）\n",
    "\n",
    "base_dt = parse_units_base_datetime(units)  # forcing 的 epoch\n",
    "tL_dt = [base_dt + dt.timedelta(seconds=float(s)) for s in tL_sec]\n",
    "\n",
    "z = np.asarray(M[\"z\"]).T.squeeze().astype(float)\n",
    "\n",
    "tauxL = np.asarray(M[\"tau13l\"])[:, 0].astype(float) * LES_TAUX_SCALE\n",
    "tauyL = np.asarray(M[\"tau23l\"])[:, 0].astype(float) * LES_TAUY_SCALE\n",
    "\n",
    "if \"Us\" in M and \"Vs\" in M:\n",
    "    usx0L = np.asarray(M[\"Us\"])[:, 0].astype(float)\n",
    "    usy0L = np.asarray(M[\"Vs\"])[:, 0].astype(float)\n",
    "    us0L  = np.sqrt(usx0L**2 + usy0L**2)\n",
    "else:\n",
    "    raise KeyError(\"LES mat missing 'Us'/'Vs' arrays for Stokes drift components.\")\n",
    "\n",
    "print(\"[forcing] start/end:\", tF_dt[0], tF_dt[-1], \"Nt=\", len(tF_dt))\n",
    "print(\"[LES]     start/end:\", tL_dt[0], tL_dt[-1], \"Nt=\", len(tL_dt))\n",
    "\n",
    "# =========================\n",
    "# plotting (ABSOLUTE time axis)\n",
    "# =========================\n",
    "fig = plt.figure(figsize=(11.5, 10.0))\n",
    "gs = fig.add_gridspec(3, 2, height_ratios=[1, 1, 1.1], hspace=0.35, wspace=0.25)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 0])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax5 = fig.add_subplot(gs[2, :])\n",
    "\n",
    "ax1.plot(tF_dt, tauxF, label=\"forcing\")\n",
    "ax1.plot(tL_dt, tauxL, \"--\", label=\"LES\")\n",
    "ax1.set_title(\"Taux\"); ax1.legend()\n",
    "\n",
    "ax2.plot(tF_dt, tauyF, label=\"forcing\")\n",
    "ax2.plot(tL_dt, tauyL, \"--\", label=\"LES\")\n",
    "ax2.set_title(\"Tauy\"); ax2.legend()\n",
    "\n",
    "ax3.plot(tF_dt, usx0F, label=\"forcing\")\n",
    "ax3.plot(tL_dt, usx0L, \"--\", label=\"LES\")\n",
    "ax3.set_title(\"Us_x (surface/top cell)\"); ax3.legend()\n",
    "\n",
    "ax4.plot(tF_dt, usy0F, label=\"forcing\")\n",
    "ax4.plot(tL_dt, usy0L, \"--\", label=\"LES\")\n",
    "ax4.set_title(\"Us_y (surface/top cell)\"); ax4.legend()\n",
    "\n",
    "ax5.plot(tF_dt, us0F, label=\"forcing |Us|\")\n",
    "ax5.plot(tL_dt, us0L, \"--\", label=\"LES |Us|\")\n",
    "ax5.set_title(\"|Us| comparison\"); ax5.legend()\n",
    "\n",
    "for ax in (ax1, ax2, ax3, ax4, ax5):\n",
    "    ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m-%d %H:%M\"))\n",
    "    ax.tick_params(axis=\"x\", rotation=25)\n",
    "\n",
    "fig.suptitle(f\"ABS time comparison (CASE {CASE})\", y=0.995, fontsize=13)\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Profile check at one time\n",
    "# =========================\n",
    "itF = PROFILE_FORC_IT\n",
    "tF_pick = tF_dt[itF]\n",
    "itL = nearest_idx_datetime(tL_dt, tF_pick)\n",
    "\n",
    "print(f\"[profile] forcing it={itF}, t={tF_pick}\")\n",
    "print(f\"[profile] LES nearest it={itL}, t={tL_dt[itL]}, Δt={(tL_dt[itL]-tF_pick).total_seconds()/60:.2f} min\")\n",
    "\n",
    "usx_band_t = usx_bands[:, itF]\n",
    "usy_band_t = usy_bands[:, itF]\n",
    "usxF_z, usyF_z, usF_z = forcing_profile_from_bands(usx_band_t, usy_band_t, k, z)\n",
    "\n",
    "usxL_z = np.asarray(M[\"Us\"])[itL, :].astype(float)\n",
    "usyL_z = np.asarray(M[\"Vs\"])[itL, :].astype(float)\n",
    "usL_z  = np.sqrt(usxL_z**2 + usyL_z**2)\n",
    "\n",
    "fig2, axs = plt.subplots(1, 3, figsize=(10.8, 3.8), sharey=True)\n",
    "axs[0].plot(usxF_z, z, label=\"forcing\"); axs[0].plot(usxL_z, z, \"--\", label=\"LES\"); axs[0].set_title(\"Usx(z)\")\n",
    "axs[1].plot(usyF_z, z, label=\"forcing\"); axs[1].plot(usyL_z, z, \"--\", label=\"LES\"); axs[1].set_title(\"Usy(z)\")\n",
    "axs[2].plot(usF_z,  z, label=\"forcing\"); axs[2].plot(usL_z,  z, \"--\", label=\"LES\"); axs[2].set_title(\"|Us|(z)\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(True, alpha=0.25)\n",
    "axs[0].set_ylabel(\"z (m, positive down)\")\n",
    "axs[2].legend(loc=\"best\")\n",
    "fig2.suptitle(f\"Profile check @ forcing time {tF_pick} (LES nearest)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bd4ac-7725-4170-9eb2-f6a7d336e856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f9b617-479c-439b-8464-5d2e619d8f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
